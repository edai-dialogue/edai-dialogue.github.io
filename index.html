<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title> ICRA'25 Workshop: Bridging Early Cognitive Development and Embodied AI for Advancing Robotic Intelligence, HOME</title>
  <meta content="Bridging Early Cognitive Development and Embodied AI for Advancing Robotic Intelligence." name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
  
  <style>
    li {
      margin: 10px 50px 10px 10px; 
    }
  </style>

  <!-- =======================================================
    Modified based on the following template.
  * Template Name: Selecao - v4.6.0
  * Template URL: https://bootstrapmade.com/selecao-bootstrap-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top d-flex align-items-center  header-transparent ">
    <div class="container d-flex align-items-center justify-content-between">
      <div class="logo"> 
        
        <!-- Uncomment below if you prefer to use an image logo -->
       <!-- <h1><a href="https://fl-icml2023.github.io/" target="blank_">ICML 2023</a></h1>  -->

       <!-- <p style="margin : 0; padding-top:0; padding-left: 80px; padding-bottom:0;  line-height:0; font-size: 10px; text-align: center;" class="green-text">
        July, 2023 
      </p> -->
      </div>

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto active" href="#hero">Home</a></li>
          <li><a class="nav-link scrollto" href="#about">About</a></li>
          <!-- <li><a class="nav-link scrollto" href="#cfp">CFP</a></li> -->
          <!-- <li><a class="nav-link scrollto" href="#awards">Awards</a></li> -->
          <li><a class="nav-link scrollto " href="#program">Program</a></li>
          <!-- <li><a class="nav-link scrollto " href="#papers">Accepted Papers</a></li> -->
          <li><a class="nav-link scrollto" href="#speaker">Speakers</a></li>
          <!-- <li><a class="nav-link scrollto" href="#panel">Panelists</a></li> -->
          <li><a class="nav-link scrollto" href="#org">Organizers</a></li>
          <!-- <li><a class="nav-link scrollto" href="#pc">Program Committee</a></li> -->
          <!-- <li><a class="nav-link scrollto" href="#sponsors">Sponsors</a></li> -->
          <!-- <li><a class="nav-link scrollto" href="#contact">Contact</a></li> -->
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->
    </div>
  </header><!-- End Header -->

 <!-- ======= Hero Section ======= -->
 <section id="hero" class="d-flex flex-column justify-content-end align-items-center">
    <div id="heroCarousel" data-bs-interval="5000" class="container carousel carousel-fade" data-bs-ride="carousel">
      <!-- Slide 1 -->
      <div class="carousel-item active">
        <div class="carousel-container">
          <h2 class="animate__animated animate__fadeInDown"> ICRA'25 Workshop: Bridging Early Cognitive Development and Embodied AI for Advancing Robotic Intelligence</h2> 
          <h2 class="animate__animated animate__fadeInDown"> Atlanta, GA 
          </h2>
          <h2 class="animate__animated animate__fadeInDown"> 2025
          </h2>
          <p class="animate__animated animate__fadeInUp">
         </p>
         <!-- <h5 class="text-white">Join our <a href="https://groups.google.com/g/fl-workshop-icml23">Google Group</a> for important updates!</h5> -->
        </div>
      </div>
    </div>

    <svg class="hero-waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28 " preserveAspectRatio="none">
      <defs>
        <path id="wave-path" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z">
      </defs>
      <g class="wave1">
        <use xlink:href="#wave-path" x="50" y="3" fill="rgba(255,255,255, .1)">
      </g>
      <g class="wave2">
        <use xlink:href="#wave-path" x="50" y="0" fill="rgba(255,255,255, .2)">
      </g>
      <g class="wave3">
        <use xlink:href="#wave-path" x="50" y="9" fill="#fff">
      </g>
    </svg>
  </section><!-- End Hero -->

  <main id="main">
    <!-- ======= About Section ======= -->
    <section id="about" class="about">
      <div class="container">
        <div class="section-title" data-aos="zoom-out">
          <h2>About</h2>
          <p>About</p>
        </div>

        <div class="row content" data-aos="fade-up">
          <div class="col-12">
            <figure class="image" style="text-align: center;">
              <img src="assets/img/organizer/ai.jpg" alt="Workshop Image" style="max-width: 100%; height: auto;">
            </figure>
          </div>
        </div>

        <div class="row content" data-aos="fade-up">
          <div>
            <p>
              Humans are often considered the most advanced and sophisticated autonomous systems, with exceptional problem-solving abilities that effortlessly adapt to dynamic and ever-changing environments. A critical foundation for these capabilities is early cognitive development, where infants and young children autonomously explore their surroundings through active sensing. They generate actions, observe outcomes, form goals, identify patterns and rules, make causal inferences, and predict future events. This spontaneous learning process occurs during a crucial phase of brain maturation and reorganization, leading to a self-organizing process marked by shifts in neural dynamics, connectivity, and the development of increasingly complex cognitive functions.
            </p>
            <p> Inspired by early cognitive development processes, this workshop aims to explore how robotic systems can be designed to emulate mechanisms of autonomous exploration and learning. By integrating active sensing, goal formation, and real-time feedback, robots can progressively acquire knowledge and enhance their decision-making capabilities. This developmental approach, supported by advancements in embodied AI, fosters self-organization and adaptability, enabling robots to interact autonomously with complex, dynamic environments. Existing robotic systems, however, often struggle to achieve the adaptability and robustness seen in humans, as they are typically designed for repetitive, predefined tasks in controlled settings. These systems face significant challenges when confronted with incomplete or ambiguous information, unforeseen scenarios, or novel situations. We contend that a crucial missing element in these robotic systems is the integration of developmental dynamics, which would drive continuous knowledge acquisition and facilitate effective decision-making through interaction with the physical world.</p>
            <p> This workshop aims to reignite the dialogue among AI/ML researchers, cognitive and neuroscientists, and roboticists to bridge the essential gap between early human cognitive development and embodied AI for advancing robotic intelligence. We envision transforming this workshop into an annual event that promotes active communication and cross-disciplinary collaboration, fostering a vibrant community and preparing a workforce for the next generation of robotics. A wide array of topics will be explored within the overarching theme of the workshop, with organizers selecting different focal areas each year to guide discussions. Topics such as neural embodied cognition, sensorimotor dynamics learning, and developmental robotics will be explored to better understand how robots can develop adaptive, intelligent behaviors.</p>
            <br>
          </div>
        </div>
      </div>
    </section><!-- End About Section -->

    <!-- ======= Program Section ======= -->
    <section id="program" class="program">
      <div class="container">
        <div class="section-title" data-aos="zoom-out">
          <h2>Program</h2>
          <p>Workshop Program</p>
        </div>
        
        <div class="row">
          <!-- <p>The following program will take place from <strong>Friday, May 31, to Saturday, June 1, Eastern Time</strong>. The workshop will be held at the <a href="https://www.parkvista.com/"><strong>Park Vista hotel</strong></a> in Gatlinburg. The meeting will be held in <strong>Garden View A,B</strong>.</p> -->

          <div class="col-md-6" style="width: 100%">
            <br>
            

            <table class="table table-striped">
              <tr><td><b>Time</b></td><td><b>Themes</b></td><td><b>Activity</b></td></tr>
          
              <tr><td>08:30 - 08:40</td><td></td><td>Opening Remarks</td></tr>
              
              <tr><td>08:40 - 09:15</td><td>Neural Embodied Cognition</td><td>Chen Yu: Embodied Intelligence in Humans and Machines</td></tr>
              <tr><td>09:15 - 09:50</td><td>Neural Embodied Cognition</td><td>Mark Wallace: Multisensory Development Scaffolds the
                Maturation of Cognitive Representations</td></tr>
              <tr><td>09:50 - 10:35</td><td>Neural Embodied Cognition</td><td>Break and Poster Session 1 (45min)</td></tr>
              
              <tr><td>10:35 - 11:10</td><td>Sensorimotor Dynamics Learning</td><td>Sehoon Ha: Understanding the Multi-Modality of Real-world
                for Autonomous Navigation</td></tr>
              <tr><td>11:10 - 11:45</td><td>Sensorimotor Dynamics Learning</td><td>Michael Yip: Learning the Language of Robot Task and
                Motion Planning</td></tr>
              <tr><td>11:45 - 12:30</td><td>Sensorimotor Dynamics Learning</td><td>Break and Poster Session 2 (45min)
              </td></tr>
              
              <tr><td>12:30 - 13:30</td><td></td><td>Lunch</td></tr>
              
              <tr><td>13:30 - 14:05</td><td>Developmental Robotics</td><td>Dorsa Sadigh: Enabling Embodied Intelligence via Large
                Scale Pretrained Models
                </td></tr>
              <tr><td>14:05 - 14:40</td><td>Developmental Robotics</td><td>Roozbeh Mottaghi: Human-Robot Collaboration at Scale</td></tr>
              <tr><td>14:40 - 15:25</td><td>Developmental Robotics</td><td>Break and Poster Session 3 (45min)</td></tr>
              
              <tr><td>15:25 - 16:25</td><td>Discussions</td><td>Panel Discussion (60min): Chen Yu, Mark Wallace, Sehoon Ha,
                Michael Yip, Dorsa Sadigh, Roozbeh Mottagh</td></tr>
              <tr><td>16:25 - 17:00</td><td>Discussions</td><td>Best Paper Award Ceremony & Concluding Remarks</td></tr>
          </table>
          
          </div>
        </div>
      </div>
    </section><!-- End Program Section -->

    <!-- ======= Speaker Section ======= -->
    <section id="speaker" class="team">
      <div class="container">
          <div class="section-title" data-aos="zoom-out">
              <h2>Talks</h2>
              <p>Invited Speakers</p>
          </div>
  
          <!-- Speaker 1: Chen Yu -->
          <div class="row">
              <div class="col-lg-12 col-md-12 d-flex align-items-stretch">
                  <div class="member" data-aos="fade-up" style="display: flex;">
                      <div class="member-img">
                          <img src="assets/img/speaker/chenyu.jpeg" class="img-fluid is-rounded" style="height: 230px; width: 900px;">
                      </div>
                      <div class="member-info" style="margin-left: 20px;">
                          <!-- <h4><a href="https://liberalarts.utexas.edu/psychology/faculty/cy2856">Chen Yu</a></h4> -->
                          <!-- <strong>The University of Texas at Austin</strong> -->
                          <!-- New content added here -->
                          <div>
                            <p style="color: black;"><strong>Talk Title: Embodied Intelligence in Humans and Machines</strong></p>
                            <p style="color: black;">
                                <a href="https://liberalarts.utexas.edu/psychology/faculty/cy2856" target="_blank">Chen Yu (University of Texas, Austin)</a> 
                                is the Charles and Sarah Seay Regents Professor in the Department of Psychology, Center for Perceptual Systems, and Institute for Neuroscience at the University of Texas at Austin. He is a
                                fellow of the Cognitive Science Society and the Association for Psychological Science. His accolades
                                include the Robert L. Fantz Memorial Award from the American Psychological Foundation, the David
                                Marr Prize from the Cognitive Science Society, and the ICIS Early Distinguished Contribution Award.
                                He has also received several best paper awards from IEEE ICDL, the Cognitive Science Society, and
                                CVPR.
                            </p>
                          </div>
                      </div>
                  </div>
              </div>
          </div>
  
          <!-- Speaker 2: VP Nguyen -->
          <div class="row">
            <div class="col-lg-12 col-md-12 d-flex align-items-stretch">
                <div class="member" data-aos="fade-up" style="display: flex;">
                    <div class="member-img">
                        <img src="assets/img/speaker/roozbeh.jpg" class="img-fluid is-rounded" style="height: 230px; width: 780px;">
                    </div>
                    <div class="member-info" style="margin-left: 20px;">
                        <div>
                            <p style="color: black;"><strong>Talk Title: Human-Robot Collaboration at Scale</strong></p>
                            <p style="color: black;">
                                <a href="https://roozbehm.info/" target="_blank">Roozbeh Mottaghi (FAIR, Meta)</a> 
                                is a Senior Research Scientist Manager at FAIR, Meta. Previously, he was the Research Manager at the Allen Institute for AI (AI2). He earned his PhD in Computer Science in 2013 from the University of California, Los Angeles, followed by a postdoctoral position in the Computer Science Department at Stanford University. His research focuses on embodied AI, reasoning via perception, and learning through interaction. His work on large-scale Embodied AI received the Outstanding Paper Award at NeurIPS 2022.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
          <div class="col-lg-12 col-md-12 d-flex align-items-stretch">
              <div class="member" data-aos="fade-up" style="display: flex;">
                  <div class="member-img">
                      <img src="assets/img/speaker/dorsa.jpeg" class="img-fluid is-rounded" style="height: 230px; width: 1050px;">
                  </div>
                  <div class="member-info" style="margin-left: 20px;">
                      <div>
                          <p style="color: black;"><strong>Talk Title: Enabling Embodied Intelligence via Large Scale Pretrained Models</strong></p>
                          <p style="color: black;">
                              <a href="https://dorsa.fyi/" target="_blank">Dorsa Sadigh ( Stanford University)</a> 
                              is an assistant professor in Computer Science and Electrical Engineering at Stanford
                              University. Her research interests lie in the intersection of robotics, learning, and control theory.
                              Specifically, she is interested in developing algorithms for safe and adaptive human-robot and human-AI interaction. Dorsa received her doctoral degree in Electrical Engineering and Computer Sciences
                              (EECS) from UC Berkeley in 2017, and received her bachelor's degree in EECS from UC Berkeley in
                              2012. She is awarded the Sloan Fellowship, NSF CAREER, ONR Young Investigator Award, AFOSR
                              Young Investigator Award, DARPA Young Faculty Award, Okawa Foundation Fellowship, MIT TR35,
                              and the IEEE RAS Early Academic Career Award.
                          </p>
                      </div>
                  </div>
              </div>
          </div>
      </div>

      

        
        
  
          <!-- Speaker 3: Aaron Buss -->
          <div class="row">
            <div class="col-lg-12 col-md-12 d-flex align-items-stretch">
                <div class="member" data-aos="fade-up" style="display: flex;">
                    <div class="member-img">
                        <img src="assets/img/speaker/Wallace.jpg" class="img-fluid is-rounded" style="height: 230px; width: 850px;">
                    </div>
                    <div class="member-info" style="margin-left: 20px;">
                        <div>
                            <p style="color: black;"><strong>Talk Title: Multisensory Development Scaffolds the Maturation of Cognitive Representations</strong></p>
                            <p style="color: black;">
                                <a href="https://vkc.vumc.org/multisensory/" target="_blank">Mark Wallace (Vanderbilt University)</a> 
                                is the holder of the Louise B. McGavock Endowed Chair in Neuroscience at Vanderbilt University and has served as the Director of the Vanderbilt Brain Institute. He is a fellow of AAAS and the Association for Psychological Science (APS). His work focuses upon the neural architecture of multisensory integration and its development. He now directs an international consortium supported by Reality Labs Research (a division of Meta) studying perceptual and cognitive development in children from birth to young adulthood in immersive, naturalistic environments.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
  
          <!-- Speaker 4: Katie Schuman -->
          <div class="row">
            <div class="col-lg-12 col-md-12 d-flex align-items-stretch">
                <div class="member" data-aos="fade-up" style="display: flex;">
                    <div class="member-img">
                        <img src="assets/img/speaker/yip.jpg" class="img-fluid is-rounded" style="height: 230px; width: 960px;">
                    </div>
                    <div class="member-info" style="margin-left: 20px;">
                        <div>
                            <p style="color: black;"><strong>Talk Title: Learning the Language of Robot Task and Motion Planning</strong></p>
                            <p style="color: black;">
                                <a href="https://yip.eng.ucsd.edu/" target="_blank">Michael Yip (UC San Diego)</a> 
                                is an Associate Professor of Electrical and Computer Engineering at UC San Diego, IEEE RAS Distinguished Lecturer, Hellman Fellow, Senior Member of the IEEE and the National Academy of Inventors, and Director of the Advanced Robotics and Controls Laboratory (ARCLab). His group currently focuses on a variety of research agendas across robotics, autonomy, artificial intelligence, and machine learning. His work has been recognized through several best paper awards and nominations at ICRA and IROS, the 2017 best paper award for IEEE Robot and Automation Letters, as well as recognitions including the NSF CAREER award and the NIH Trailblazer award.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
          <div class="col-lg-12 col-md-12 d-flex align-items-stretch">
              <div class="member" data-aos="fade-up" style="display: flex;">
                  <div class="member-img">
                      <img src="assets/img/speaker/ha.jpg" class="img-fluid is-rounded" style="height: 230px; width: 960px;">
                  </div>
                  <div class="member-info" style="margin-left: 20px;">
                      <div>
                          <p style="color: black;"><strong>Talk Title: Understanding the Multi-Modality of Real-world for Autonomous Navigation</strong></p>
                          <p style="color: black;">
                              <a href="https://faculty.cc.gatech.edu/~sha9/" target="_blank">Sehoon Ha (Georgia Institute of Technology)</a> 
                              is an Assistant Professor at the Georgia Institute of Technology. His research lies at the intersection of character animation, robotics, and artificial intelligence, with a focus on creating autonomous agents capable of dynamic and realistic interactions in virtual and physical environments. Prior to joining Georgia Tech, he was a research scientist at Google and Disney Research Pittsburgh. He received his PhD in Computer Science from Georgia Tech in 2015 under the supervision of Dr. C. Karen Liu and holds a B.S. degree in Computer Science from KAIST. His work aims to bridge the gap between computational models of human behavior and AI-driven embodied intelligence.
                          </p>
                      </div>
                  </div>
              </div>
          </div>
      </div>
      
        
  
      </div>
  </section>
  
    <!-- ======= Organization Section ======= -->
    <section id="org" class="team">
      <div class="container">
        <div class="section-title" data-aos="zoom-out">
          <h2>Organization</h2>
          <p>Workshop Organizers</p>
        </div>
        <!-- <p style="font-size: 24px; font-weight: bold;">
          Steering Committee
        </p> -->

        <div class="row">
          <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
            <div class="member" data-aos="fade-up">
              <div class="member-img">
                <img src="assets/img/organizer/qi-sqare.jpg" class="img-fluid is-rounded" style="height: 300px; width: 100%">
              </div>
              <div class="member-info">
                <h4><a href="https://aicip.github.io/">Hairong Qi</a></h4>
                <strong>The University of Tennessee, Knoxville</strong>
              </div>
            </div>
          </div>
          
        <!-- Organizer 2: Daniela Corbetta -->
        <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
          <div class="member" data-aos="fade-up">
            <div class="member-img">
              <img src="assets/img/organizer/corbetta.jpg" class="img-fluid is-rounded" style="height: 300px; width: 100%">
            </div>
            <div class="member-info">
              <h4><a href="https://psychology.utk.edu/people/daniela-corbetta/">Daniela Corbetta</a></h4>
              <strong>The University of Tennessee, Knoxville</strong>
            </div>
          </div>
        </div>

        <!-- Organizer 3: Fei Liu -->
        <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
          <div class="member" data-aos="fade-up">
            <div class="member-img">
              <img src="assets/img/organizer/fei.jpg" class="img-fluid is-rounded" style="height: 300px; width: 100%">
            </div>
            <div class="member-info">
              <h4><a href="https://lnnx2006.github.io/">Fei Liu</a></h4>
              <strong>The University of Tennessee, Knoxville</strong>
            </div>
          </div>
        </div>

        <!-- Organizer 4: Soheil Kolouri -->
        <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
          <div class="member" data-aos="fade-up">
            <div class="member-img">
              <img src="assets/img/organizer/SoheilKolouri.jpeg" class="img-fluid is-rounded" style="height: 300px; width: 100%">
            </div>
            <div class="member-info">
              <h4><a href="https://engineering.vanderbilt.edu/bio/?pid=soheil-kolouri">Soheil Kolouri</a></h4>
              <strong>Vanderbilt University</strong>
            </div>
          </div>
        </div>

        <!-- Organizer 5: Sihong He -->
        <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
          <div class="member" data-aos="fade-up">
            <div class="member-img">
              <img src="assets/img/organizer/he.jpg" class="img-fluid is-rounded" style="height: 300px; width: 100%">
            </div>
            <div class="member-info">
              <h4><a href="https://sihonghe.com/">Sihong He</a></h4>
              <strong>The University of Texas at Arlington</strong>
            </div>
          </div>
        </div>

        <!-- Organizer 6: Jian Liu -->
        <div class="col-lg-3 col-md-6 d-flex align-items-stretch">
          <div class="member" data-aos="fade-up">
            <div class="member-img">
              <img src="assets/img/organizer/jian.jpeg" class="img-fluid is-rounded" style="height: 300px; width: 100%">
            </div>
            <div class="member-info">
              <h4><a href="https://web.eecs.utk.edu/~jliu/">Jian Liu</a></h4>
              <strong>The University of Tennessee, Knoxville</strong>
            </div>
          </div>
        </div>
        
        
        
    </section><!-- End Organization Section -->

    <!-- ======= Sponsors Section ======= -->
    
  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="credits">
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a> and <a href="https://doc2dial.github.io/workshop2022/">DialDoc@ACL2022</a>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>
</html>
